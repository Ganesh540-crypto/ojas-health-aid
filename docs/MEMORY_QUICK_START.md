# Memory System Quick Start Guide

## ‚úÖ What's Been Done

### Phase 1: Profile Summary ‚úì (COMPLETED)
- ‚úÖ Fixed error in `memoryFunctions.ts` (line 175)
- ‚úÖ Added `profileSummary` section to CoreMemoryBlock
- ‚úÖ AI can now maintain natural language summaries of user info
- ‚úÖ New function: `updateProfileSummary()`

### Phase 2: Vector Embeddings ‚úì (CODE READY)
- ‚úÖ Created `embeddingService.ts` - Generates 768-dim vectors
- ‚úÖ Created `vectorMemory.ts` - Firebase vector storage
- ‚úÖ Added `searchSemanticMemory()` function
- ‚úÖ Added `storeImportantMemory()` function
- ‚úÖ Fallback to local search if Firebase unavailable

## üöÄ How to Use

### 1. Test Profile Summary (Works Now!)

The AI can now maintain a profile summary:

```typescript
// User: "I'm 32, work as a software engineer, have type 2 diabetes"
// AI automatically calls:
updateProfileSummary({
  personalDetails: "32-year-old software engineer",
  healthSummary: "Type 2 diabetes, monitoring blood sugar"
});

// Later in NEW chat:
// User: "Do you remember my age?"
// AI: "Yes, you're 32 years old and work as a software engineer."
```

**Files:**
- `src/lib/memoryEnhanced.ts` - Memory storage
- `src/lib/memoryFunctions.ts` - AI functions

### 2. Enable Vector Search (Requires Firebase Setup)

**Step 1: Deploy to Firebase (5 mins)**

```bash
cd c:\Users\ganes\Downloads\Ojas-ai

# Deploy Firestore rules and indexes
firebase deploy --only firestore
```

**Step 2: Test Vector Embeddings**

```typescript
// In browser console or test file:
import { embeddingService } from './lib/embeddingService';

// Generate embedding
const vector = await embeddingService.generateEmbedding(
  "My blood sugar was 150 this morning"
);
console.log('Vector dimensions:', vector.length); // Should be 768
```

**Step 3: Store and Search**

```typescript
import { vectorMemory } from './lib/vectorMemory';

// Store health data
await vectorMemory.storeMemory(
  "Blood sugar reading: 150 mg/dL on October 17 morning",
  "health_data"
);

// Search semantically (different words, same meaning!)
const results = await vectorMemory.searchMemories(
  "What was my glucose level?"  // Uses "glucose" instead of "blood sugar"
);

console.log(results[0].content); 
// ‚Üí "Blood sugar reading: 150 mg/dL..."
console.log(results[0].similarity);
// ‚Üí 0.92 (very similar!)
```

### 3. AI Integration (Next Step)

Enable memory functions in AI router:

```typescript
// In src/lib/aiRouter.ts

import { memoryManagementFunctions, executeMemoryFunction } from './memoryFunctions';

// Add to Gemini model config
const model = genai.getGenerativeModel({
  model: 'gemini-2.5-flash',
  tools: [{
    functionDeclarations: Object.values(memoryManagementFunctions)
  }]
});

// Handle function calls in response
if (response.functionCall) {
  const result = await executeMemoryFunction(
    response.functionCall.name,
    response.functionCall.args
  );
  // Send result back to model
}
```

## üìä Real-World Examples

### Example 1: Health Tracking

```
User: "My blood sugar was 150 this morning after breakfast"
AI: [Calls storeImportantMemory]
‚úì Stored in local memory
‚úì Stored in Firebase with vector embedding

[Next day, different chat]
User: "What was my glucose reading yesterday?"
AI: [Calls searchSemanticMemory("glucose reading")]
AI: "Your blood sugar was 150 mg/dL yesterday morning after breakfast."
```

### Example 2: Medication Memory

```
User: "I take metformin 500mg twice daily"
AI: [Calls updateProfileSummary + storeImportantMemory]

[Week later]
User: "What medication am I on?"
AI: [Reads from profileSummary]
AI: "You're taking metformin 500mg twice daily."
```

### Example 3: Cross-Chat Recall

```
[Chat 1 - Oct 10]
User: "I'm allergic to penicillin"
AI: [Stores in vector memory]

[Chat 2 - Oct 17]
User: "Do you know my allergies?"
AI: [Searches vector memory across ALL chats]
AI: "Yes, you're allergic to penicillin."
```

## üéØ Key Features

| Feature | How It Works | Benefit |
|---------|--------------|---------|
| **Profile Summary** | AI maintains natural language summaries | Quick recall of user basics |
| **Semantic Search** | Finds "diabetes" when searching "blood sugar" | Understands meaning, not just words |
| **Cross-Chat Memory** | Search across all conversations | Never forget user info |
| **Firebase Sync** | Stored in cloud | Works on all devices |
| **Fallback** | Uses local keyword search if Firebase fails | Always works |

## üß™ Testing Checklist

### ‚úÖ Phase 1 Tests (Works Now)
- [ ] AI can update profile summary
- [ ] Profile summary persists in localStorage
- [ ] Profile summary included in context

### ‚è≥ Phase 2 Tests (After Firebase Setup)
- [ ] Generate embedding for text
- [ ] Store memory in Firebase
- [ ] Search by semantic similarity
- [ ] Fallback to keyword search works
- [ ] AI can call memory functions

## üí∞ Cost Breakdown

**For 1000 users, 30 days:**

| Service | Usage | Cost |
|---------|-------|------|
| Gemini Embeddings | 50/day/user √ó 30 days | $15 |
| Firebase Storage | 5GB | $0.90 |
| Firestore Reads | 50K/day | $0.30 |
| Firestore Writes | 10K/day | $0.18 |
| **Total** | | **~$16.50/month** |

**Per user: ~$0.015/month (‚Çπ1.25)** ‚úÖ

## üîç Monitoring

### Check Memory Stats

```typescript
import { enhancedMemoryStore } from './lib/memoryEnhanced';
import { vectorMemory } from './lib/vectorMemory';

// Local memory stats
const stats = enhancedMemoryStore.getMemoryStats();
console.log('Local:', stats);

// Firebase vector memory stats
const vectorStats = await vectorMemory.getStats();
console.log('Firebase:', vectorStats);
```

### Debug Mode

```typescript
// Enable detailed logging
localStorage.setItem('debug_memory', 'true');

// Check what's being stored
console.log(enhancedMemoryStore.getCoreMemoryString());
console.log(enhancedMemoryStore.getRecallMemoryString());
```

## üö® Troubleshooting

### "User not authenticated"
```typescript
// Check if user is logged in
import { auth } from './lib/firebase';
console.log('User:', auth.currentUser?.uid);
```

### "Embedding API error"
```typescript
// Check API key
console.log('API Key:', import.meta.env.VITE_GEMINI_API_KEY?.substring(0, 10) + '...');
```

### Vector search returns no results
```typescript
// Check similarity threshold
const results = await vectorMemory.searchMemories(query, {
  similarityThreshold: 0.5  // Lower = more results
});
```

## üìö API Reference

### Memory Functions Available to AI

1. **`updateProfileSummary`** - Update user profile summary
2. **`archiveImportantFact`** - Store in archival memory
3. **`searchMemory`** - Keyword search (local)
4. **`searchSemanticMemory`** - Vector search (Firebase)
5. **`storeImportantMemory`** - Store with vector embedding
6. **`updateConversationContext`** - Update current topic
7. **`getHealthHistory`** - Get recent health data

### TypeScript Interfaces

```typescript
interface CoreMemoryBlock {
  userProfile: { name?, age?, healthConditions?, medications?, allergies? };
  conversationContext: { currentTopic?, language? };
  profileSummary: { 
    personalDetails?, 
    healthSummary?, 
    importantPreferences?,
    communicationStyle? 
  };
}

interface VectorMemoryItem {
  content: string;
  embedding: number[]; // 768 dimensions
  type: 'health_data' | 'conversation' | 'user_preference' | 'fact';
  timestamp: number;
  similarity?: number; // Only in search results
}
```

## ‚úÖ Next Steps

1. **Test profile summary** - Should work immediately
2. **Deploy to Firebase** - `firebase deploy --only firestore`
3. **Test vector embeddings** - Generate and store
4. **Enable in AI router** - Add function calling
5. **Monitor usage** - Check costs and performance

---

**Status: Phase 1 ‚úÖ Complete | Phase 2 ‚è≥ Ready for Testing**

Need help? Check `VECTOR_EMBEDDINGS_IMPLEMENTATION.md` for detailed setup guide.
